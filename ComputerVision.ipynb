{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "feature_extractor_3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "20pfZV-DsU4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "import os\n",
        "import time\n",
        "import copy\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from torch.autograd import Variable\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft5aglXotUCJ",
        "colab_type": "code",
        "outputId": "45c004d2-21a2-4059-bff8-e02694ee0856",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sfw7W9vosU4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_pathlist(root='/content/drive/My Drive/data'):\n",
        "    pathlist = {'train' : [],\n",
        "                'val' : [],\n",
        "                'test' : []}\n",
        "\n",
        "    for r, d, f in os.walk(root):\n",
        "        for path in f:\n",
        "            if '.avi' not in path:\n",
        "                continue\n",
        "            group = int(path.split('_')[-2])\n",
        "            full_path = os.path.join(r, path)\n",
        "\n",
        "            if group <= 20:\n",
        "                split = 'train'\n",
        "            elif group <= 22:\n",
        "                split = 'val'\n",
        "            else:\n",
        "                split = 'test'\n",
        "\n",
        "            pathlist[split].append(full_path)\n",
        "    \n",
        "    return pathlist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2djblhAsU4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pathlist = create_pathlist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQQyoNWIsU4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = {'train' : transforms.Compose([transforms.RandomResizedCrop(196, scale=[0.8, 1.0]),\n",
        "                                           transforms.RandomHorizontalFlip(),\n",
        "                                           transforms.RandomRotation(24),\n",
        "                                           transforms.CenterCrop(144),\n",
        "                                           transforms.ToTensor(),\n",
        "                                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
        "             \n",
        "             'val' : transforms.Compose([transforms.RandomResizedCrop(196, scale=[0.8, 1.0]),\n",
        "                                         transforms.CenterCrop(144),\n",
        "                                         transforms.ToTensor(),\n",
        "                                         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])]),\n",
        "             \n",
        "             'test' : transforms.Compose([transforms.RandomResizedCrop(196, scale=[0.8, 1.0]),\n",
        "                                          transforms.CenterCrop(144),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gsKfSFfsU4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VideoFolder(Dataset):\n",
        "    def __init__(self, root, split, transform=None):\n",
        "        self.pathlist = create_pathlist(root)[split]\n",
        "        self.split = split\n",
        "        self.transform = transform\n",
        "        self.batch_size = 16\n",
        "        self.num = 0\n",
        "        self.classes = {'shooting' : 0,\n",
        "                        'biking' : 1,\n",
        "                        'diving' : 2,\n",
        "                        'golf' : 3,\n",
        "                        'riding' : 4,\n",
        "                        'juggle' : 5,\n",
        "                        'swing' : 6,\n",
        "                        'tennis' : 7,\n",
        "                        'jumping' : 8,\n",
        "                        'spiking' : 9,\n",
        "                        'walk' : 10}\n",
        "        \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.pathlist)\n",
        "    \n",
        "\n",
        "    def video_read(self, j):\n",
        "        path = self.pathlist[j]\n",
        "\n",
        "        label = self.classes[path.split('/')[-1].split('_')[1]]\n",
        "\n",
        "        capture = cv2.VideoCapture(path)\n",
        "\n",
        "        num_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        frame_list = np.random.choice(num_frames, self.batch_size, replace=False)\n",
        "\n",
        "        image_frames = []\n",
        "        labels = [label for _ in range(self.batch_size)]\n",
        "\n",
        "        for i in range(num_frames):\n",
        "            if i not in frame_list:\n",
        "                continue\n",
        "\n",
        "            running, frame = capture.read()\n",
        "            if not running:\n",
        "                break\n",
        "                \n",
        "            image = Image.fromarray(frame)\n",
        "            image = self.transform(image)\n",
        "\n",
        "            image_frames.append(image)\n",
        "\n",
        "        return image_frames, label\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        image_frames, label = self.video_read(index)\n",
        "        \n",
        "        images = torch.stack([frame for frame in image_frames])\n",
        "        labels = torch.stack([torch.LongTensor([label for _ in range(self.batch_size)])]).reshape((-1))\n",
        "        \n",
        "        return (images, labels)\n",
        "    \n",
        "    \n",
        "    def __iter__(self):\n",
        "        return self\n",
        "    \n",
        "    \n",
        "    def __next__(self):\n",
        "        try:\n",
        "            num = self.num\n",
        "            self.num += 1\n",
        "            return self[num]\n",
        "        except:\n",
        "            self.num = 0\n",
        "            raise StopIteration"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7dnFgqSsU4P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datasets = {x : VideoFolder('/content/drive/My Drive/data', x, transform[x]) for x in ['train', 'val', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGaoIgB0zRma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpu = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXs2MerRsU4U",
        "colab_type": "code",
        "outputId": "e5e054e3-c5a6-4079-c285-3baa4ddff224",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "model = models.vgg16(pretrained=True)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 11)\n",
        "        )\n",
        "\n",
        "model.cuda()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace)\n",
              "    (2): Dropout(p=0.5)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace)\n",
              "    (5): Dropout(p=0.5)\n",
              "    (6): Linear(in_features=4096, out_features=11, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Ly0R36sU4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.classifier.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYyCwD-UH2--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, criterion, num_epochs=10, lr=0.01):\n",
        "    start = time.time()\n",
        "    best_model_state = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for images, labels in datasets['train']:\n",
        "            images = Variable(images.cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "        print(\"Train:               Epoch: {}, Loss: {}\".format(epoch+1, loss.item()))\n",
        "\n",
        "        correct = 0\n",
        "\n",
        "        for images, labels in datasets['val']:\n",
        "            images = Variable(images.cuda())\n",
        "            labels = Variable(labels.cuda())\n",
        "\n",
        "            with torch.set_grad_enabled(False):\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "            \n",
        "            _, predicted = torch.max(outputs.data, 1) \n",
        "            correct += torch.sum(predicted.cpu() == labels.cpu()).item()\n",
        "        \n",
        "        print(correct)\n",
        "        accuracy = correct / len(datasets['val'])\n",
        "        print(\"Validation:          Epoch: {}, Loss: {}, Accuracy: {}\".format(epoch+1, str(loss.item()), str(accuracy)))\n",
        "\n",
        "        if accuracy > best_acc:\n",
        "            best_model_state = copy.deepcopy(model.state_dict)\n",
        "            best_acc = accuracy\n",
        "\n",
        "    stop = time.time()\n",
        "\n",
        "    print(\"Time taken: {:.4f}\".format(stop-start))\n",
        "    print(\"Best accuracy: {:.4f} %\".format(100 * best_acc))\n",
        "    \n",
        "    model = model.load_state_dict(best_model_state)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Yx2SSql6IcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = train(model, optimizer, criterion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51crgHanEJiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}